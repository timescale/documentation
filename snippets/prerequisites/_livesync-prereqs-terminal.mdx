import { SERVICE_LONG, SERVICE_SHORT, PG, PG_CONNECTOR } from '/snippets/vars.mdx';

Best practice is to use an [Ubuntu EC2 instance](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EC2_GetStarted.html#ec2-launch-instance) hosted in the same region as your
{SERVICE_LONG} to move data. That is, the machine you run the commands on to move your
data from your source database to your target {SERVICE_LONG}.

Before you move your data:

- Create a target {SERVICE_LONG}.

  Each {SERVICE_LONG} has a single {PG} instance that supports the
  most popular extensions. {SERVICE_LONG}s do not support tablespaces,
  and there is no superuser associated with a {SERVICE_SHORT}.
  Best practice is to create a {SERVICE_LONG} with at least 8 CPUs for a smoother experience. A higher-spec instance
  can significantly reduce the overall migration window.

- To ensure that maintenance does not run while migration is in progress, best practice is to adjust the maintenance window.

- Ensure that the source {PG} instance and the target {SERVICE_LONG} have the same extensions installed.

  The {PG_CONNECTOR} does not create extensions on the target. If the table uses column types from an extension,
  first create the extension on the target {SERVICE_LONG} before syncing the table.

- [Install Docker](https://docs.docker.com/engine/install/) on your sync machine.

  For a better experience, use a 4 CPU/16GB EC2 instance or greater to run the {PG_CONNECTOR}.

- Install the [{PG} client tools](/integrations/integrate/psql) on your sync machine.

  This includes `psql`, `pg_dump`, `pg_dumpall`, and `vacuumdb` commands.